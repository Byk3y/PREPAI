/**
 * Content Extraction Utilities
 * Handles PDF, Image OCR, Audio transcription, and text chunking
 */

// Imports are dynamic to avoid initialization issues

interface OCRResult {
  text: string;
  confidence: number; // 0-100
  metadata: {
    engine: 'tesseract' | 'google-vision';
    lowQuality: boolean; // true if confidence < threshold or very short text
    language: string;
    processingTime: number;
    warning?: string; // Optional warning message for very short text
  };
}

/**
 * URL Security Validation Result
 */
interface UrlValidationResult {
  allowed: boolean;
  reason?: string;
}

/**
 * SECURITY: Validate URL to prevent SSRF attacks
 * Blocks:
 * - Non-HTTP(S) protocols (file://, javascript:, data:, etc.)
 * - Localhost and loopback addresses
 * - Private IP ranges (10.x.x.x, 172.16-31.x.x, 192.168.x.x)
 * - Cloud metadata endpoints (169.254.169.254)
 * - Link-local addresses
 */
export function validateUrlSecurity(urlString: string): UrlValidationResult {
  try {
    const url = new URL(urlString);

    // 1. Block non-HTTP(S) protocols
    if (!['http:', 'https:'].includes(url.protocol)) {
      return {
        allowed: false,
        reason: `Protocol "${url.protocol}" not allowed. Only HTTP/HTTPS URLs are supported.`
      };
    }

    const hostname = url.hostname.toLowerCase();

    // 2. Block localhost and loopback addresses
    if (hostname === 'localhost' ||
      hostname === '127.0.0.1' ||
      hostname === '::1' ||
      hostname === '0.0.0.0' ||
      hostname.endsWith('.localhost') ||
      hostname.endsWith('.local')) {
      return {
        allowed: false,
        reason: 'Localhost and local network URLs are not allowed for security reasons.'
      };
    }

    // 3. Check if it's an IP address and validate
    const ipv4Pattern = /^(\d{1,3})\.(\d{1,3})\.(\d{1,3})\.(\d{1,3})$/;
    const ipMatch = hostname.match(ipv4Pattern);

    if (ipMatch) {
      const [, a, b, c, d] = ipMatch.map(Number);

      // Validate each octet is 0-255
      if (a > 255 || b > 255 || c > 255 || d > 255) {
        return { allowed: false, reason: 'Invalid IP address format.' };
      }

      // Block private IP ranges (RFC 1918)
      // 10.0.0.0 - 10.255.255.255
      if (a === 10) {
        return { allowed: false, reason: 'Private network IPs (10.x.x.x) are not allowed.' };
      }

      // 172.16.0.0 - 172.31.255.255
      if (a === 172 && b >= 16 && b <= 31) {
        return { allowed: false, reason: 'Private network IPs (172.16-31.x.x) are not allowed.' };
      }

      // 192.168.0.0 - 192.168.255.255
      if (a === 192 && b === 168) {
        return { allowed: false, reason: 'Private network IPs (192.168.x.x) are not allowed.' };
      }

      // Block link-local addresses (169.254.x.x) - includes AWS/cloud metadata
      if (a === 169 && b === 254) {
        return { allowed: false, reason: 'Link-local and cloud metadata endpoints are not allowed.' };
      }

      // Block loopback range (127.x.x.x)
      if (a === 127) {
        return { allowed: false, reason: 'Loopback addresses are not allowed.' };
      }

      // Block broadcast (255.255.255.255)
      if (a === 255 && b === 255 && c === 255 && d === 255) {
        return { allowed: false, reason: 'Broadcast addresses are not allowed.' };
      }

      // Block 0.0.0.0/8
      if (a === 0) {
        return { allowed: false, reason: 'Reserved IP range is not allowed.' };
      }
    }

    // 4. Block IPv6 private/local addresses
    if (hostname.startsWith('[')) {
      // IPv6 addresses are enclosed in brackets
      const ipv6 = hostname.slice(1, -1).toLowerCase();
      if (ipv6 === '::1' ||
        ipv6.startsWith('fe80:') ||  // Link-local
        ipv6.startsWith('fc') ||     // Unique local
        ipv6.startsWith('fd')) {     // Unique local
        return { allowed: false, reason: 'Private/local IPv6 addresses are not allowed.' };
      }
    }

    // 5. Block common internal service hostnames
    const blockedHostPatterns = [
      /^internal\./i,
      /^intranet\./i,
      /^admin\./i,
      /^metadata\./i,
      /\.internal$/i,
      /\.corp$/i,
      /\.lan$/i,
    ];

    for (const pattern of blockedHostPatterns) {
      if (pattern.test(hostname)) {
        return { allowed: false, reason: 'Internal/corporate hostnames are not allowed.' };
      }
    }

    // URL passed all security checks
    return { allowed: true };

  } catch (error) {
    return {
      allowed: false,
      reason: 'Invalid URL format. Please provide a valid HTTP or HTTPS URL.'
    };
  }
}

// Import SmartPDFExtractor statically (dynamic imports don't get bundled)
import { SmartPDFExtractor } from './pdf/orchestrator.ts';

/**
 * Extract text from PDF file using Smart PDF Extractor
 * - Primary: Gemini 2.0 Flash (multimodal AI, NotebookLM-grade)
 * - Fallback: pdfjs-dist (local extraction)
 * - Intelligent fallback on rate limits or errors
 */
export async function extractPDF(fileBuffer: Uint8Array): Promise<string> {
  console.log('[extractPDF] START - Buffer size:', fileBuffer.length);
  const startTime = Date.now();

  // SECURITY: Validate file magic bytes to ensure it's actually a PDF
  const { validateFileMagicBytes } = await import('./validation.ts');
  const fileValidation = validateFileMagicBytes(fileBuffer, 'pdf');
  if (!fileValidation.isValid) {
    console.error('[extractPDF] SECURITY: File magic byte validation failed:', fileValidation.error);
    throw new Error(fileValidation.error || 'Invalid PDF file');
  }
  console.log('[extractPDF] File magic bytes validated - confirmed PDF');

  try {
    console.log('[extractPDF] Importing SmartPDFExtractor...');
    // Use SmartPDFExtractor with Gemini → pdfjs fallback
    const extractor = new SmartPDFExtractor();
    console.log('[extractPDF] SmartPDFExtractor initialized successfully');

    console.log('[extractPDF] Starting extraction...');
    const result = await extractor.extract(fileBuffer);
    console.log('[extractPDF] Extraction completed successfully');

    const processingTime = Date.now() - startTime;
    console.log(
      `[extractPDF] SUCCESS: ${result.text.length} chars extracted in ${processingTime}ms ` +
      `using ${result.metadata.service} (quality: ${result.metadata.quality}, ` +
      `attempts: ${result.metadata.attemptCount})`
    );

    // Log fallbacks for monitoring
    if (result.metadata.fallbacksUsed.length > 0) {
      console.warn('[extractPDF] Fallbacks used:', result.metadata.fallbacksUsed);
    }

    return result.text;
  } catch (error: unknown) {
    const errorMsg = error instanceof Error ? error.message : String(error);
    const errorStack = error instanceof Error ? error.stack : 'No stack trace';
    console.error('[extractPDF] ERROR:', errorMsg);
    console.error('[extractPDF] ERROR STACK:', errorStack);
    console.error('[extractPDF] ERROR OBJECT:', JSON.stringify(error, null, 2));
    throw new Error(`PDF extraction error: ${errorMsg}`);
  }
}

/**
 * Extract text from image using OCR
 * Primary: Gemini 2.0 Flash (multimodal AI, same as PDF extraction)
 * Fallback: Google Vision API (if explicitly requested)
 */
export async function extractImageText(
  fileBuffer: Uint8Array,
  options: {
    useGoogleVision?: boolean; // default: false (use Gemini)
    confidenceThreshold?: number; // default: 70
  } = {}
): Promise<OCRResult> {
  const confidenceThreshold = options.confidenceThreshold ?? 70;

  // SECURITY: Validate file magic bytes to ensure it's actually an image
  const { validateFileMagicBytes } = await import('./validation.ts');
  const fileValidation = validateFileMagicBytes(fileBuffer, 'image');
  if (!fileValidation.isValid) {
    console.error('[extractImageText] SECURITY: File magic byte validation failed:', fileValidation.error);
    throw new Error(fileValidation.error || 'Invalid image file');
  }
  console.log('[extractImageText] File magic bytes validated - confirmed image:', fileValidation.detectedType);

  if (options.useGoogleVision) {
    // Google Vision OCR (fallback option)
    return await googleVisionOCR(fileBuffer, confidenceThreshold);
  } else {
    // Gemini OCR (primary - multimodal AI)
    return await geminiOCR(fileBuffer, confidenceThreshold);
  }
}

/**
 * Tesseract OCR implementation
 * NOTE: Tesseract.js is NOT compatible with Deno Edge Functions (Worker.prototype.constructor not implemented)
 * TODO: Implement cloud OCR (Google Vision, AWS Textract, etc.) for production use
 */
async function tesseractOCR(
  fileBuffer: Uint8Array,
  confidenceThreshold: number
): Promise<OCRResult> {
  const startTime = Date.now();

  // Tesseract.js requires Web Workers which are not fully supported in Deno Edge Functions
  // Return a placeholder response until cloud OCR is implemented
  console.warn('Tesseract OCR is disabled in Edge Functions. Cloud OCR integration needed.');

  return {
    text: '[Image OCR temporarily disabled - Cloud OCR integration coming soon]',
    confidence: 0,
    metadata: {
      engine: 'tesseract',
      lowQuality: true,
      language: 'eng',
      processingTime: Date.now() - startTime,
      warning: 'Image OCR is temporarily disabled. Tesseract.js is not compatible with Deno Edge Functions. Cloud OCR (Google Vision, AWS Textract) integration coming soon.',
    },
  };
}

/**
 * Gemini OCR - Multimodal AI text extraction
 * Uses Gemini 2.0 Flash for high-quality text extraction from images
 * Same API as PDF extraction - handles handwriting, watermarks, complex layouts
 */
async function geminiOCR(
  fileBuffer: Uint8Array,
  confidenceThreshold: number
): Promise<OCRResult> {
  const { getRequiredEnv } = await import('./env.ts');
  const apiKey = getRequiredEnv('GOOGLE_AI_API_KEY');

  const startTime = Date.now();

  try {
    // Convert buffer to base64 using chunked conversion to avoid stack overflow
    const CHUNK_SIZE = 8192; // Process 8KB chunks
    let binaryString = '';

    for (let i = 0; i < fileBuffer.length; i += CHUNK_SIZE) {
      const chunk = fileBuffer.slice(i, i + CHUNK_SIZE);
      binaryString += String.fromCharCode.apply(null, Array.from(chunk));
    }

    const base64Image = btoa(binaryString);

    // Detect MIME type from buffer (simple check)
    let mimeType = 'image/jpeg';
    if (fileBuffer[0] === 0x89 && fileBuffer[1] === 0x50) {
      mimeType = 'image/png';
    } else if (fileBuffer[0] === 0xFF && fileBuffer[1] === 0xD8) {
      mimeType = 'image/jpeg';
    }

    // Call Gemini 2.0 Flash API
    const response = await fetch(
      `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${apiKey}`,
      {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          contents: [
            {
              parts: [
                {
                  inline_data: {
                    mime_type: mimeType,
                    data: base64Image,
                  },
                },
                {
                  text: 'Extract all text from this image. Return only the extracted text without any commentary or explanation. If there is no text, respond with "No text detected".',
                },
              ],
            },
          ],
          generationConfig: {
            temperature: 0.1,
            topP: 1,
            topK: 32,
            maxOutputTokens: 4096,
          },
        }),
      }
    );

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`Gemini API error: ${response.status} ${errorText}`);
    }

    const data = await response.json();
    const text = data.candidates?.[0]?.content?.parts?.[0]?.text || '';

    if (!text || text.trim() === '' || text.includes('No text detected')) {
      throw new Error('No text detected in image');
    }

    const processingTime = Date.now() - startTime;

    // Estimate confidence based on text length and processing success
    // Longer text = higher confidence in extraction quality
    let confidence = 90; // Base confidence for Gemini
    if (text.length < 50) {
      confidence = 75; // Lower confidence for very short text
    } else if (text.length < 100) {
      confidence = 85;
    }

    return {
      text: text.trim(),
      confidence,
      metadata: {
        engine: 'google-vision', // Keep same engine type for compatibility
        lowQuality: confidence < confidenceThreshold,
        language: 'eng',
        processingTime,
      },
    };
  } catch (error: unknown) {
    const message = error instanceof Error ? error.message : String(error);
    throw new Error(`Gemini OCR error: ${message}`);
  }
}

/**
 * Google Vision OCR (fallback option)
 * Premium OCR for handwritten notes and low-quality photos
 */
async function googleVisionOCR(
  fileBuffer: Uint8Array,
  confidenceThreshold: number
): Promise<OCRResult> {
  const { getRequiredEnv } = await import('./env.ts');
  const apiKey = getRequiredEnv('GOOGLE_VISION_API_KEY');

  const startTime = Date.now();

  try {
    // Convert buffer to base64 using chunked conversion to avoid stack overflow
    const CHUNK_SIZE = 8192; // Process 8KB chunks
    let binaryString = '';

    for (let i = 0; i < fileBuffer.length; i += CHUNK_SIZE) {
      const chunk = fileBuffer.slice(i, i + CHUNK_SIZE);
      binaryString += String.fromCharCode.apply(null, Array.from(chunk));
    }

    const base64Image = btoa(binaryString);

    // Call Google Vision API
    const response = await fetch(
      `https://vision.googleapis.com/v1/images:annotate?key=${apiKey}`,
      {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          requests: [
            {
              image: { content: base64Image },
              features: [{ type: 'TEXT_DETECTION' }],
            },
          ],
        }),
      }
    );

    if (!response.ok) {
      throw new Error(`Google Vision API error: ${response.status}`);
    }

    const data = await response.json();
    const textAnnotations = data.responses?.[0]?.textAnnotations;

    if (!textAnnotations || textAnnotations.length === 0) {
      throw new Error('No text detected in image');
    }

    // First annotation contains full text
    const text = textAnnotations[0].description;
    const processingTime = Date.now() - startTime;

    // Google Vision doesn't provide confidence per image, estimate from detection
    const confidence = 85; // Assume good quality if detected

    return {
      text: text.trim(),
      confidence,
      metadata: {
        engine: 'google-vision',
        lowQuality: confidence < confidenceThreshold,
        language: 'eng', // TODO: Detect from response
        processingTime,
      },
    };
  } catch (error: unknown) {
    const message = error instanceof Error ? error.message : String(error);
    throw new Error(`Google Vision OCR error: ${message}`);
  }
}

/**
 * Transcribe audio to text using Gemini 2.0 Flash (Multimodal AI)
 * Faster, cheaper, and more accurate than AssemblyAI for study materials
 */
export async function transcribeAudio(audioUrl: string): Promise<string> {
  const { getRequiredEnv } = await import('./env.ts');
  const apiKey = getRequiredEnv('GOOGLE_AI_API_KEY');

  console.log('[transcribeAudio] START - Fetching audio from:', audioUrl);
  const startTime = Date.now();

  try {
    // Step 1: Fetch audio file
    const audioResponse = await fetch(audioUrl);
    if (!audioResponse.ok) {
      throw new Error(`Failed to fetch audio: ${audioResponse.status}`);
    }
    const audioBuffer = new Uint8Array(await audioResponse.arrayBuffer());
    console.log('[transcribeAudio] Downloaded buffer size:', audioBuffer.length);

    // SECURITY: Validate file magic bytes to ensure it's actually audio
    const { validateFileMagicBytes } = await import('./validation.ts');
    const fileValidation = validateFileMagicBytes(audioBuffer, 'audio');
    if (!fileValidation.isValid) {
      console.error('[transcribeAudio] SECURITY: File magic byte validation failed:', fileValidation.error);
      throw new Error(fileValidation.error || 'Invalid audio file');
    }
    console.log('[transcribeAudio] File magic bytes validated - confirmed audio:', fileValidation.detectedType);

    // Step 2: Convert to base64 using chunked conversion (avoid call stack issues)
    const CHUNK_SIZE = 8192;
    let binaryString = '';
    for (let i = 0; i < audioBuffer.length; i += CHUNK_SIZE) {
      const chunk = audioBuffer.slice(i, i + CHUNK_SIZE);
      binaryString += String.fromCharCode.apply(null, Array.from(chunk));
    }
    const base64Audio = btoa(binaryString);

    // Step 3: Detect MIME type (fallback to mp3)
    let mimeType = 'audio/mpeg';
    if (audioUrl.toLowerCase().endsWith('.wav')) mimeType = 'audio/wav';
    else if (audioUrl.toLowerCase().endsWith('.m4a')) mimeType = 'audio/mp4';
    else if (audioUrl.toLowerCase().endsWith('.aac')) mimeType = 'audio/aac';
    else if (audioUrl.toLowerCase().endsWith('.ogg')) mimeType = 'audio/ogg';
    else if (audioUrl.toLowerCase().endsWith('.flac')) mimeType = 'audio/flac';

    // Step 4: Call Gemini 2.0 Flash API (multimodal)
    console.log('[transcribeAudio] Requesting transcription from Gemini...');
    const response = await fetch(
      `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${apiKey}`,
      {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          contents: [
            {
              parts: [
                {
                  inline_data: {
                    mime_type: mimeType,
                    data: base64Audio,
                  },
                },
                {
                  text: 'You are an expert academic transcriptionist. Provide a precise and cleanly formatted transcription of this audio. Break it into logical paragraphs. Include speaker labels (Speaker A, Speaker B, etc.) if there are multiple people. Return only the transcript text without any commentary.',
                },
              ],
            },
          ],
          generationConfig: {
            temperature: 0.1,
            maxOutputTokens: 20480, // Allow for long recordings
          },
        }),
      }
    );

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`Gemini Audio API error: ${response.status} ${errorText}`);
    }

    const data = await response.json();
    const text = data.candidates?.[0]?.content?.parts?.[0]?.text || '';

    if (!text || text.trim() === '') {
      throw new Error('Gemini returned an empty transcription');
    }

    const duration = Date.now() - startTime;
    console.log(`[transcribeAudio] SUCCESS: Transcribed in ${duration}ms`);

    return text.trim();
  } catch (error: unknown) {
    const message = error instanceof Error ? error.message : String(error);
    console.error('[transcribeAudio] ERROR:', message);
    throw new Error(`Audio transcription error: ${message}`);
  }
}

/**
 * Website content extraction result
 */
interface WebsiteExtractionResult {
  text: string;
  title: string | null;
  metadata: {
    source: 'jina-reader' | 'direct-fetch' | 'gemini';
    url: string;
    processingTime: number;
    contentLength: number;
    warning?: string;
  };
}

/**
 * Extract content from a website URL using Jina Reader
 * Primary: Jina Reader API (LLM-optimized markdown extraction)
 * Fallback: Direct fetch + Gemini cleanup
 * 
 * @param url - The website URL to extract content from
 * @returns Extracted content in markdown format
 */
export async function extractWebsiteContent(url: string): Promise<WebsiteExtractionResult> {
  const { getOptionalEnv } = await import('./env.ts');

  console.log('[extractWebsiteContent] START - URL:', url);
  const startTime = Date.now();

  // SECURITY: Validate URL to prevent SSRF attacks
  const securityCheck = validateUrlSecurity(url);
  if (!securityCheck.allowed) {
    console.error(`[extractWebsiteContent] SECURITY BLOCK: ${securityCheck.reason}`);
    throw new Error(securityCheck.reason || 'URL blocked for security reasons');
  }

  // Try Jina Reader first (primary method)
  try {
    const result = await extractWithJinaReader(url, startTime);
    return result;
  } catch (jinaError: unknown) {
    const jinaMsg = jinaError instanceof Error ? jinaError.message : String(jinaError);
    console.warn(`[extractWebsiteContent] Jina Reader failed: ${jinaMsg}`);

    // Fallback to direct fetch + basic extraction
    try {
      const result = await extractWithDirectFetch(url, startTime);
      return result;
    } catch (directError: unknown) {
      const directMsg = directError instanceof Error ? directError.message : String(directError);
      console.error(`[extractWebsiteContent] Direct fetch also failed: ${directMsg}`);
      throw new Error(`Website extraction failed: ${jinaMsg}. Fallback also failed: ${directMsg}`);
    }
  }
}

/**
 * Extract content using Jina Reader API
 * https://r.jina.ai/{url} returns clean content optimized for LLMs
 * Uses JSON response format for structured data and removes images to save tokens
 */
async function extractWithJinaReader(
  url: string,
  startTime: number
): Promise<WebsiteExtractionResult> {
  const { getOptionalEnv } = await import('./env.ts');
  const jinaApiKey = getOptionalEnv('JINA_API_KEY', '');

  // Jina Reader URL - prepend r.jina.ai to any URL
  const jinaUrl = `https://r.jina.ai/${url}`;

  console.log('[extractWithJinaReader] Calling Jina Reader:', jinaUrl);

  // Optimized headers for study content:
  // - JSON response for structured parsing (title, content, url)
  // - No images to save tokens (we only need text for study materials)
  const headers: Record<string, string> = {
    'Accept': 'application/json',
    'X-Retain-Images': 'none',
  };

  // Add API key if available (increases rate limits from ~20/min to higher)
  if (jinaApiKey) {
    headers['Authorization'] = `Bearer ${jinaApiKey}`;
  }

  const response = await fetch(jinaUrl, {
    method: 'GET',
    headers,
  });

  if (!response.ok) {
    const errorText = await response.text();
    throw new Error(`Jina Reader API error: ${response.status} - ${errorText.substring(0, 200)}`);
  }

  const processingTime = Date.now() - startTime;

  // Parse JSON response
  const data = await response.json();

  // Jina JSON response structure:
  // { code: 200, status: 20000, data: { title, url, content, ... } }
  const content = data?.data?.content || data?.content || '';
  const title = data?.data?.title || data?.title || null;
  const responseUrl = data?.data?.url || data?.url || url;

  // Validate content
  if (!content || content.trim().length < 50) {
    throw new Error('Jina Reader returned insufficient content');
  }

  console.log(`[extractWithJinaReader] SUCCESS: ${content.length} chars extracted in ${processingTime}ms`);
  if (title) {
    console.log(`[extractWithJinaReader] Title: "${title}"`);
  }

  return {
    text: content.trim(),
    title: title ? title.trim() : null,
    metadata: {
      source: 'jina-reader',
      url: responseUrl,
      processingTime,
      contentLength: content.length,
    },
  };
}

/**
 * Fallback: Direct fetch + basic HTML-to-text extraction
 * Uses Gemini to clean up the extracted content
 */
async function extractWithDirectFetch(
  url: string,
  startTime: number
): Promise<WebsiteExtractionResult> {
  const { getRequiredEnv } = await import('./env.ts');

  console.log('[extractWithDirectFetch] Fetching URL directly:', url);

  // Fetch the page
  const response = await fetch(url, {
    headers: {
      'User-Agent': 'Mozilla/5.0 (compatible; BrigoBot/1.0; +https://brigo.app)',
      'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
    },
  });

  if (!response.ok) {
    throw new Error(`Failed to fetch URL: ${response.status}`);
  }

  const html = await response.text();

  if (!html || html.length < 100) {
    throw new Error('Page returned insufficient content');
  }

  // Basic HTML cleanup - remove scripts, styles, and extract text
  let cleanedHtml = html
    // Remove script and style tags with content
    .replace(/<script\b[^<]*(?:(?!<\/script>)<[^<]*)*<\/script>/gi, '')
    .replace(/<style\b[^<]*(?:(?!<\/style>)<[^<]*)*<\/style>/gi, '')
    // Remove HTML comments
    .replace(/<!--[\s\S]*?-->/g, '')
    // Remove SVG content
    .replace(/<svg\b[^<]*(?:(?!<\/svg>)<[^<]*)*<\/svg>/gi, '')
    // Remove navigation and footer (common patterns)
    .replace(/<nav\b[^<]*(?:(?!<\/nav>)<[^<]*)*<\/nav>/gi, '')
    .replace(/<footer\b[^<]*(?:(?!<\/footer>)<[^<]*)*<\/footer>/gi, '')
    .replace(/<header\b[^<]*(?:(?!<\/header>)<[^<]*)*<\/header>/gi, '');

  // Extract title
  let title: string | null = null;
  const titleMatch = html.match(/<title[^>]*>([^<]+)<\/title>/i);
  if (titleMatch) {
    title = titleMatch[1].trim();
  }

  // Use Gemini to extract and clean the content
  const apiKey = getRequiredEnv('GOOGLE_AI_API_KEY');

  // Truncate HTML if too long (Gemini has context limits)
  const maxHtmlLength = 100000; // ~25k tokens
  if (cleanedHtml.length > maxHtmlLength) {
    cleanedHtml = cleanedHtml.substring(0, maxHtmlLength);
  }

  const geminiResponse = await fetch(
    `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${apiKey}`,
    {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        contents: [{
          parts: [{
            text: `Extract the main article/content from this HTML page. Return only the extracted content in clean markdown format. Remove navigation, ads, footers, and other non-content elements. Preserve headings, lists, and important formatting.

HTML:
${cleanedHtml}`,
          }],
        }],
        generationConfig: {
          temperature: 0.1,
          maxOutputTokens: 8192,
        },
      }),
    }
  );

  if (!geminiResponse.ok) {
    // If Gemini fails, return basic text extraction
    const basicText = cleanedHtml
      .replace(/<[^>]+>/g, ' ')
      .replace(/\s+/g, ' ')
      .trim();

    const processingTime = Date.now() - startTime;

    return {
      text: basicText,
      title,
      metadata: {
        source: 'direct-fetch',
        url,
        processingTime,
        contentLength: basicText.length,
        warning: 'Content extracted with basic HTML parsing (Gemini cleanup unavailable)',
      },
    };
  }

  const data = await geminiResponse.json();
  const extractedText = data.candidates?.[0]?.content?.parts?.[0]?.text || '';

  if (!extractedText || extractedText.trim().length < 50) {
    throw new Error('Gemini returned insufficient extracted content');
  }

  const processingTime = Date.now() - startTime;

  console.log(`[extractWithDirectFetch] SUCCESS with Gemini cleanup: ${extractedText.length} chars in ${processingTime}ms`);

  return {
    text: extractedText.trim(),
    title,
    metadata: {
      source: 'gemini',
      url,
      processingTime,
      contentLength: extractedText.length,
    },
  };
}

/**
 * Chunk text for RAG embeddings
 * Uses semantic chunking (paragraph-based) rather than arbitrary splits
 */
export function chunkText(text: string, maxChunkTokens = 800): string[] {
  // Split by double newlines (paragraphs)
  const paragraphs = text.split(/\n\n+/).filter((p) => p.trim().length > 0);

  const chunks: string[] = [];
  let currentChunk = '';

  for (const para of paragraphs) {
    // Rough token estimate: ~4 chars per token
    const currentTokens = currentChunk.length / 4;
    const paraTokens = para.length / 4;

    if (currentTokens + paraTokens > maxChunkTokens && currentChunk) {
      // Current chunk full, save and start new one
      chunks.push(currentChunk.trim());
      currentChunk = para;
    } else {
      // Add paragraph to current chunk
      currentChunk += (currentChunk ? '\n\n' : '') + para;
    }
  }

  // Add final chunk
  if (currentChunk.trim()) {
    chunks.push(currentChunk.trim());
  }

  return chunks;
}

/**
 * Estimate token count (rough approximation)
 * For more accuracy, use tiktoken library
 */
export function estimateTokens(text: string): number {
  // Rough estimate: 1 token ≈ 4 characters
  return Math.ceil(text.length / 4);
}
